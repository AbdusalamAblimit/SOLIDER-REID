{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70dafb40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/server/miniconda3/envs/mmpose-abu/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# CKPT FILE: pretrained/best_coco_AP_epoch_210.pth\n",
      "# TYPE: <class 'dict'>\n",
      "# TOP-LEVEL KEYS (3): ['meta', 'state_dict', 'message_hub']\n",
      "# STATE_DICT found at: state_dict  (keys=165)\n",
      "# TOTAL TENSORS: 165  TOTAL PARAMS: 90M\n",
      "# GROUP COUNT (by first prefix before dot):\n",
      "- backbone: 149\n",
      "- head: 16\n",
      "# SAMPLE KEYS (first 30):\n",
      "backbone.pos_embed                                                               (1, 192, 768) torch.float32\n",
      "backbone.patch_embed.projection.weight                                           (768, 3, 16, 16) torch.float32\n",
      "backbone.patch_embed.projection.bias                                             (768,) torch.float32\n",
      "backbone.layers.0.ln1.weight                                                     (768,) torch.float32\n",
      "backbone.layers.0.ln1.bias                                                       (768,) torch.float32\n",
      "backbone.layers.0.attn.qkv.weight                                                (2304, 768) torch.float32\n",
      "backbone.layers.0.attn.qkv.bias                                                  (2304,) torch.float32\n",
      "backbone.layers.0.attn.proj.weight                                               (768, 768) torch.float32\n",
      "backbone.layers.0.attn.proj.bias                                                 (768,) torch.float32\n",
      "backbone.layers.0.ln2.weight                                                     (768,) torch.float32\n",
      "backbone.layers.0.ln2.bias                                                       (768,) torch.float32\n",
      "backbone.layers.0.ffn.layers.0.0.weight                                          (3072, 768) torch.float32\n",
      "backbone.layers.0.ffn.layers.0.0.bias                                            (3072,) torch.float32\n",
      "backbone.layers.0.ffn.layers.1.weight                                            (768, 3072) torch.float32\n",
      "backbone.layers.0.ffn.layers.1.bias                                              (768,) torch.float32\n",
      "backbone.layers.1.ln1.weight                                                     (768,) torch.float32\n",
      "backbone.layers.1.ln1.bias                                                       (768,) torch.float32\n",
      "backbone.layers.1.attn.qkv.weight                                                (2304, 768) torch.float32\n",
      "backbone.layers.1.attn.qkv.bias                                                  (2304,) torch.float32\n",
      "backbone.layers.1.attn.proj.weight                                               (768, 768) torch.float32\n",
      "backbone.layers.1.attn.proj.bias                                                 (768,) torch.float32\n",
      "backbone.layers.1.ln2.weight                                                     (768,) torch.float32\n",
      "backbone.layers.1.ln2.bias                                                       (768,) torch.float32\n",
      "backbone.layers.1.ffn.layers.0.0.weight                                          (3072, 768) torch.float32\n",
      "backbone.layers.1.ffn.layers.0.0.bias                                            (3072,) torch.float32\n",
      "backbone.layers.1.ffn.layers.1.weight                                            (768, 3072) torch.float32\n",
      "backbone.layers.1.ffn.layers.1.bias                                              (768,) torch.float32\n",
      "backbone.layers.2.ln1.weight                                                     (768,) torch.float32\n",
      "backbone.layers.2.ln1.bias                                                       (768,) torch.float32\n",
      "backbone.layers.2.attn.qkv.weight                                                (2304, 768) torch.float32\n",
      "# --------------------------------------------------------------------------------\n",
      "# FULL LIST (name -> shape, dtype):\n",
      "backbone.pos_embed                                                               (1, 192, 768) torch.float32\n",
      "backbone.patch_embed.projection.weight                                           (768, 3, 16, 16) torch.float32\n",
      "backbone.patch_embed.projection.bias                                             (768,) torch.float32\n",
      "backbone.layers.0.ln1.weight                                                     (768,) torch.float32\n",
      "backbone.layers.0.ln1.bias                                                       (768,) torch.float32\n",
      "backbone.layers.0.attn.qkv.weight                                                (2304, 768) torch.float32\n",
      "backbone.layers.0.attn.qkv.bias                                                  (2304,) torch.float32\n",
      "backbone.layers.0.attn.proj.weight                                               (768, 768) torch.float32\n",
      "backbone.layers.0.attn.proj.bias                                                 (768,) torch.float32\n",
      "backbone.layers.0.ln2.weight                                                     (768,) torch.float32\n",
      "backbone.layers.0.ln2.bias                                                       (768,) torch.float32\n",
      "backbone.layers.0.ffn.layers.0.0.weight                                          (3072, 768) torch.float32\n",
      "backbone.layers.0.ffn.layers.0.0.bias                                            (3072,) torch.float32\n",
      "backbone.layers.0.ffn.layers.1.weight                                            (768, 3072) torch.float32\n",
      "backbone.layers.0.ffn.layers.1.bias                                              (768,) torch.float32\n",
      "backbone.layers.1.ln1.weight                                                     (768,) torch.float32\n",
      "backbone.layers.1.ln1.bias                                                       (768,) torch.float32\n",
      "backbone.layers.1.attn.qkv.weight                                                (2304, 768) torch.float32\n",
      "backbone.layers.1.attn.qkv.bias                                                  (2304,) torch.float32\n",
      "backbone.layers.1.attn.proj.weight                                               (768, 768) torch.float32\n",
      "backbone.layers.1.attn.proj.bias                                                 (768,) torch.float32\n",
      "backbone.layers.1.ln2.weight                                                     (768,) torch.float32\n",
      "backbone.layers.1.ln2.bias                                                       (768,) torch.float32\n",
      "backbone.layers.1.ffn.layers.0.0.weight                                          (3072, 768) torch.float32\n",
      "backbone.layers.1.ffn.layers.0.0.bias                                            (3072,) torch.float32\n",
      "backbone.layers.1.ffn.layers.1.weight                                            (768, 3072) torch.float32\n",
      "backbone.layers.1.ffn.layers.1.bias                                              (768,) torch.float32\n",
      "backbone.layers.2.ln1.weight                                                     (768,) torch.float32\n",
      "backbone.layers.2.ln1.bias                                                       (768,) torch.float32\n",
      "backbone.layers.2.attn.qkv.weight                                                (2304, 768) torch.float32\n",
      "backbone.layers.2.attn.qkv.bias                                                  (2304,) torch.float32\n",
      "backbone.layers.2.attn.proj.weight                                               (768, 768) torch.float32\n",
      "backbone.layers.2.attn.proj.bias                                                 (768,) torch.float32\n",
      "backbone.layers.2.ln2.weight                                                     (768,) torch.float32\n",
      "backbone.layers.2.ln2.bias                                                       (768,) torch.float32\n",
      "backbone.layers.2.ffn.layers.0.0.weight                                          (3072, 768) torch.float32\n",
      "backbone.layers.2.ffn.layers.0.0.bias                                            (3072,) torch.float32\n",
      "backbone.layers.2.ffn.layers.1.weight                                            (768, 3072) torch.float32\n",
      "backbone.layers.2.ffn.layers.1.bias                                              (768,) torch.float32\n",
      "backbone.layers.3.ln1.weight                                                     (768,) torch.float32\n",
      "backbone.layers.3.ln1.bias                                                       (768,) torch.float32\n",
      "backbone.layers.3.attn.qkv.weight                                                (2304, 768) torch.float32\n",
      "backbone.layers.3.attn.qkv.bias                                                  (2304,) torch.float32\n",
      "backbone.layers.3.attn.proj.weight                                               (768, 768) torch.float32\n",
      "backbone.layers.3.attn.proj.bias                                                 (768,) torch.float32\n",
      "backbone.layers.3.ln2.weight                                                     (768,) torch.float32\n",
      "backbone.layers.3.ln2.bias                                                       (768,) torch.float32\n",
      "backbone.layers.3.ffn.layers.0.0.weight                                          (3072, 768) torch.float32\n",
      "backbone.layers.3.ffn.layers.0.0.bias                                            (3072,) torch.float32\n",
      "backbone.layers.3.ffn.layers.1.weight                                            (768, 3072) torch.float32\n",
      "backbone.layers.3.ffn.layers.1.bias                                              (768,) torch.float32\n",
      "backbone.layers.4.ln1.weight                                                     (768,) torch.float32\n",
      "backbone.layers.4.ln1.bias                                                       (768,) torch.float32\n",
      "backbone.layers.4.attn.qkv.weight                                                (2304, 768) torch.float32\n",
      "backbone.layers.4.attn.qkv.bias                                                  (2304,) torch.float32\n",
      "backbone.layers.4.attn.proj.weight                                               (768, 768) torch.float32\n",
      "backbone.layers.4.attn.proj.bias                                                 (768,) torch.float32\n",
      "backbone.layers.4.ln2.weight                                                     (768,) torch.float32\n",
      "backbone.layers.4.ln2.bias                                                       (768,) torch.float32\n",
      "backbone.layers.4.ffn.layers.0.0.weight                                          (3072, 768) torch.float32\n",
      "backbone.layers.4.ffn.layers.0.0.bias                                            (3072,) torch.float32\n",
      "backbone.layers.4.ffn.layers.1.weight                                            (768, 3072) torch.float32\n",
      "backbone.layers.4.ffn.layers.1.bias                                              (768,) torch.float32\n",
      "backbone.layers.5.ln1.weight                                                     (768,) torch.float32\n",
      "backbone.layers.5.ln1.bias                                                       (768,) torch.float32\n",
      "backbone.layers.5.attn.qkv.weight                                                (2304, 768) torch.float32\n",
      "backbone.layers.5.attn.qkv.bias                                                  (2304,) torch.float32\n",
      "backbone.layers.5.attn.proj.weight                                               (768, 768) torch.float32\n",
      "backbone.layers.5.attn.proj.bias                                                 (768,) torch.float32\n",
      "backbone.layers.5.ln2.weight                                                     (768,) torch.float32\n",
      "backbone.layers.5.ln2.bias                                                       (768,) torch.float32\n",
      "backbone.layers.5.ffn.layers.0.0.weight                                          (3072, 768) torch.float32\n",
      "backbone.layers.5.ffn.layers.0.0.bias                                            (3072,) torch.float32\n",
      "backbone.layers.5.ffn.layers.1.weight                                            (768, 3072) torch.float32\n",
      "backbone.layers.5.ffn.layers.1.bias                                              (768,) torch.float32\n",
      "backbone.layers.6.ln1.weight                                                     (768,) torch.float32\n",
      "backbone.layers.6.ln1.bias                                                       (768,) torch.float32\n",
      "backbone.layers.6.attn.qkv.weight                                                (2304, 768) torch.float32\n",
      "backbone.layers.6.attn.qkv.bias                                                  (2304,) torch.float32\n",
      "backbone.layers.6.attn.proj.weight                                               (768, 768) torch.float32\n",
      "backbone.layers.6.attn.proj.bias                                                 (768,) torch.float32\n",
      "backbone.layers.6.ln2.weight                                                     (768,) torch.float32\n",
      "backbone.layers.6.ln2.bias                                                       (768,) torch.float32\n",
      "backbone.layers.6.ffn.layers.0.0.weight                                          (3072, 768) torch.float32\n",
      "backbone.layers.6.ffn.layers.0.0.bias                                            (3072,) torch.float32\n",
      "backbone.layers.6.ffn.layers.1.weight                                            (768, 3072) torch.float32\n",
      "backbone.layers.6.ffn.layers.1.bias                                              (768,) torch.float32\n",
      "backbone.layers.7.ln1.weight                                                     (768,) torch.float32\n",
      "backbone.layers.7.ln1.bias                                                       (768,) torch.float32\n",
      "backbone.layers.7.attn.qkv.weight                                                (2304, 768) torch.float32\n",
      "backbone.layers.7.attn.qkv.bias                                                  (2304,) torch.float32\n",
      "backbone.layers.7.attn.proj.weight                                               (768, 768) torch.float32\n",
      "backbone.layers.7.attn.proj.bias                                                 (768,) torch.float32\n",
      "backbone.layers.7.ln2.weight                                                     (768,) torch.float32\n",
      "backbone.layers.7.ln2.bias                                                       (768,) torch.float32\n",
      "backbone.layers.7.ffn.layers.0.0.weight                                          (3072, 768) torch.float32\n",
      "backbone.layers.7.ffn.layers.0.0.bias                                            (3072,) torch.float32\n",
      "backbone.layers.7.ffn.layers.1.weight                                            (768, 3072) torch.float32\n",
      "backbone.layers.7.ffn.layers.1.bias                                              (768,) torch.float32\n",
      "backbone.layers.8.ln1.weight                                                     (768,) torch.float32\n",
      "backbone.layers.8.ln1.bias                                                       (768,) torch.float32\n",
      "backbone.layers.8.attn.qkv.weight                                                (2304, 768) torch.float32\n",
      "backbone.layers.8.attn.qkv.bias                                                  (2304,) torch.float32\n",
      "backbone.layers.8.attn.proj.weight                                               (768, 768) torch.float32\n",
      "backbone.layers.8.attn.proj.bias                                                 (768,) torch.float32\n",
      "backbone.layers.8.ln2.weight                                                     (768,) torch.float32\n",
      "backbone.layers.8.ln2.bias                                                       (768,) torch.float32\n",
      "backbone.layers.8.ffn.layers.0.0.weight                                          (3072, 768) torch.float32\n",
      "backbone.layers.8.ffn.layers.0.0.bias                                            (3072,) torch.float32\n",
      "backbone.layers.8.ffn.layers.1.weight                                            (768, 3072) torch.float32\n",
      "backbone.layers.8.ffn.layers.1.bias                                              (768,) torch.float32\n",
      "backbone.layers.9.ln1.weight                                                     (768,) torch.float32\n",
      "backbone.layers.9.ln1.bias                                                       (768,) torch.float32\n",
      "backbone.layers.9.attn.qkv.weight                                                (2304, 768) torch.float32\n",
      "backbone.layers.9.attn.qkv.bias                                                  (2304,) torch.float32\n",
      "backbone.layers.9.attn.proj.weight                                               (768, 768) torch.float32\n",
      "backbone.layers.9.attn.proj.bias                                                 (768,) torch.float32\n",
      "backbone.layers.9.ln2.weight                                                     (768,) torch.float32\n",
      "backbone.layers.9.ln2.bias                                                       (768,) torch.float32\n",
      "backbone.layers.9.ffn.layers.0.0.weight                                          (3072, 768) torch.float32\n",
      "backbone.layers.9.ffn.layers.0.0.bias                                            (3072,) torch.float32\n",
      "backbone.layers.9.ffn.layers.1.weight                                            (768, 3072) torch.float32\n",
      "backbone.layers.9.ffn.layers.1.bias                                              (768,) torch.float32\n",
      "backbone.layers.10.ln1.weight                                                    (768,) torch.float32\n",
      "backbone.layers.10.ln1.bias                                                      (768,) torch.float32\n",
      "backbone.layers.10.attn.qkv.weight                                               (2304, 768) torch.float32\n",
      "backbone.layers.10.attn.qkv.bias                                                 (2304,) torch.float32\n",
      "backbone.layers.10.attn.proj.weight                                              (768, 768) torch.float32\n",
      "backbone.layers.10.attn.proj.bias                                                (768,) torch.float32\n",
      "backbone.layers.10.ln2.weight                                                    (768,) torch.float32\n",
      "backbone.layers.10.ln2.bias                                                      (768,) torch.float32\n",
      "backbone.layers.10.ffn.layers.0.0.weight                                         (3072, 768) torch.float32\n",
      "backbone.layers.10.ffn.layers.0.0.bias                                           (3072,) torch.float32\n",
      "backbone.layers.10.ffn.layers.1.weight                                           (768, 3072) torch.float32\n",
      "backbone.layers.10.ffn.layers.1.bias                                             (768,) torch.float32\n",
      "backbone.layers.11.ln1.weight                                                    (768,) torch.float32\n",
      "backbone.layers.11.ln1.bias                                                      (768,) torch.float32\n",
      "backbone.layers.11.attn.qkv.weight                                               (2304, 768) torch.float32\n",
      "backbone.layers.11.attn.qkv.bias                                                 (2304,) torch.float32\n",
      "backbone.layers.11.attn.proj.weight                                              (768, 768) torch.float32\n",
      "backbone.layers.11.attn.proj.bias                                                (768,) torch.float32\n",
      "backbone.layers.11.ln2.weight                                                    (768,) torch.float32\n",
      "backbone.layers.11.ln2.bias                                                      (768,) torch.float32\n",
      "backbone.layers.11.ffn.layers.0.0.weight                                         (3072, 768) torch.float32\n",
      "backbone.layers.11.ffn.layers.0.0.bias                                           (3072,) torch.float32\n",
      "backbone.layers.11.ffn.layers.1.weight                                           (768, 3072) torch.float32\n",
      "backbone.layers.11.ffn.layers.1.bias                                             (768,) torch.float32\n",
      "backbone.ln1.weight                                                              (768,) torch.float32\n",
      "backbone.ln1.bias                                                                (768,) torch.float32\n",
      "head.pose_head.deconv_layers.0.weight                                            (768, 256, 4, 4) torch.float32\n",
      "head.pose_head.deconv_layers.1.weight                                            (256,) torch.float32\n",
      "head.pose_head.deconv_layers.1.bias                                              (256,) torch.float32\n",
      "head.pose_head.deconv_layers.1.running_mean                                      (256,) torch.float32\n",
      "head.pose_head.deconv_layers.1.running_var                                       (256,) torch.float32\n",
      "head.pose_head.deconv_layers.1.num_batches_tracked                               () torch.int64\n",
      "head.pose_head.deconv_layers.3.weight                                            (256, 256, 4, 4) torch.float32\n",
      "head.pose_head.deconv_layers.4.weight                                            (256,) torch.float32\n",
      "head.pose_head.deconv_layers.4.bias                                              (256,) torch.float32\n",
      "head.pose_head.deconv_layers.4.running_mean                                      (256,) torch.float32\n",
      "head.pose_head.deconv_layers.4.running_var                                       (256,) torch.float32\n",
      "head.pose_head.deconv_layers.4.num_batches_tracked                               () torch.int64\n",
      "head.pose_head.final_layer.weight                                                (17, 256, 1, 1) torch.float32\n",
      "head.pose_head.final_layer.bias                                                  (17,) torch.float32\n",
      "head.vis_head.2.weight                                                           (17, 768) torch.float32\n",
      "head.vis_head.2.bias                                                             (17,) torch.float32\n",
      "# --------------------------------------------------------------------------------\n",
      "# STRIPPED NAMES (model./module./keypoint_head.→head.) PREVIEW (first 30):\n",
      "backbone.pos_embed                                                               (1, 192, 768) torch.float32\n",
      "backbone.patch_embed.projection.weight                                           (768, 3, 16, 16) torch.float32\n",
      "backbone.patch_embed.projection.bias                                             (768,) torch.float32\n",
      "backbone.layers.0.ln1.weight                                                     (768,) torch.float32\n",
      "backbone.layers.0.ln1.bias                                                       (768,) torch.float32\n",
      "backbone.layers.0.attn.qkv.weight                                                (2304, 768) torch.float32\n",
      "backbone.layers.0.attn.qkv.bias                                                  (2304,) torch.float32\n",
      "backbone.layers.0.attn.proj.weight                                               (768, 768) torch.float32\n",
      "backbone.layers.0.attn.proj.bias                                                 (768,) torch.float32\n",
      "backbone.layers.0.ln2.weight                                                     (768,) torch.float32\n",
      "backbone.layers.0.ln2.bias                                                       (768,) torch.float32\n",
      "backbone.layers.0.ffn.layers.0.0.weight                                          (3072, 768) torch.float32\n",
      "backbone.layers.0.ffn.layers.0.0.bias                                            (3072,) torch.float32\n",
      "backbone.layers.0.ffn.layers.1.weight                                            (768, 3072) torch.float32\n",
      "backbone.layers.0.ffn.layers.1.bias                                              (768,) torch.float32\n",
      "backbone.layers.1.ln1.weight                                                     (768,) torch.float32\n",
      "backbone.layers.1.ln1.bias                                                       (768,) torch.float32\n",
      "backbone.layers.1.attn.qkv.weight                                                (2304, 768) torch.float32\n",
      "backbone.layers.1.attn.qkv.bias                                                  (2304,) torch.float32\n",
      "backbone.layers.1.attn.proj.weight                                               (768, 768) torch.float32\n",
      "backbone.layers.1.attn.proj.bias                                                 (768,) torch.float32\n",
      "backbone.layers.1.ln2.weight                                                     (768,) torch.float32\n",
      "backbone.layers.1.ln2.bias                                                       (768,) torch.float32\n",
      "backbone.layers.1.ffn.layers.0.0.weight                                          (3072, 768) torch.float32\n",
      "backbone.layers.1.ffn.layers.0.0.bias                                            (3072,) torch.float32\n",
      "backbone.layers.1.ffn.layers.1.weight                                            (768, 3072) torch.float32\n",
      "backbone.layers.1.ffn.layers.1.bias                                              (768,) torch.float32\n",
      "backbone.layers.2.ln1.weight                                                     (768,) torch.float32\n",
      "backbone.layers.2.ln1.bias                                                       (768,) torch.float32\n",
      "backbone.layers.2.attn.qkv.weight                                                (2304, 768) torch.float32\n",
      "\n",
      "[OK] 完整键名与形状已写入：pretrained/ckpt_dump_best_coco_AP_epoch_210.pth_20251020_210340.txt\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "import os, sys, re, json, time\n",
    "from collections import defaultdict\n",
    "import torch\n",
    "\n",
    "CANDIDATES = ['state_dict', 'model', 'state_dict_ema', 'ema', 'module']\n",
    "\n",
    "def human(n):\n",
    "    for unit in ['','K','M','B']:\n",
    "        if abs(n) < 1000.0:\n",
    "            return f\"{n:,.0f}{unit}\"\n",
    "        n /= 1000.0\n",
    "    return f\"{n:.1f}T\"\n",
    "\n",
    "def find_state_dict(obj):\n",
    "    \"\"\"\n",
    "    Return (state_dict, origin_key) where state_dict is a flat dict[str, Tensor]\n",
    "    \"\"\"\n",
    "    if isinstance(obj, dict):\n",
    "        # 1) 常见键\n",
    "        for k in CANDIDATES:\n",
    "            if k in obj and isinstance(obj[k], dict) and any(isinstance(v, torch.Tensor) for v in obj[k].values()):\n",
    "                return obj[k], k\n",
    "        # 2) 任何含 tensor 的子字典\n",
    "        for k, v in obj.items():\n",
    "            if isinstance(v, dict) and any(isinstance(t, torch.Tensor) for t in v.values()):\n",
    "                return v, k\n",
    "        # 3) 根就是 state_dict\n",
    "        if any(isinstance(v, torch.Tensor) for v in obj.values()):\n",
    "            return obj, '<root>'\n",
    "    raise RuntimeError(\"未能在 ckpt 中找到像 state_dict 的字典（里面含有 tensor）。\")\n",
    "\n",
    "def strip_prefix(name):\n",
    "    # 仅用于可选对齐观察，不改变主打印；把常见前缀去掉方便你比对\n",
    "    for p in ('model.', 'module.'):\n",
    "        if name.startswith(p):\n",
    "            name = name[len(p):]\n",
    "            break\n",
    "    name = re.sub(r'^keypoint_head\\.', 'head.', name)\n",
    "    return name\n",
    "\n",
    "def main(path, save_all=True):\n",
    "    assert os.path.isfile(path), f\"文件不存在: {path}\"\n",
    "    obj = torch.load(path, map_location='cpu')\n",
    "    ts  = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "    out = os.path.join(os.path.dirname(path), f\"ckpt_dump_{os.path.basename(path)}_{ts}.txt\")\n",
    "\n",
    "    lines = []\n",
    "    lines.append(f\"# CKPT FILE: {path}\")\n",
    "    lines.append(f\"# TYPE: {type(obj)}\")\n",
    "    if isinstance(obj, dict):\n",
    "        toplvl_keys = list(obj.keys())\n",
    "        lines.append(f\"# TOP-LEVEL KEYS ({len(toplvl_keys)}): {toplvl_keys}\")\n",
    "\n",
    "    # 取真正的 state_dict\n",
    "    sd, origin = find_state_dict(obj)\n",
    "    lines.append(f\"# STATE_DICT found at: {origin}  (keys={len(sd)})\")\n",
    "\n",
    "    # 统计\n",
    "    total_params = 0\n",
    "    groups = defaultdict(int)   # 前缀计数\n",
    "    shapes = {}\n",
    "    dtypes = {}\n",
    "    for k, v in sd.items():\n",
    "        n = v.numel()\n",
    "        total_params += n\n",
    "        head = k.split('.')[0]\n",
    "        groups[head] += 1\n",
    "        shapes[k] = tuple(v.shape)\n",
    "        dtypes[k] = str(v.dtype)\n",
    "\n",
    "    lines.append(f\"# TOTAL TENSORS: {len(sd)}  TOTAL PARAMS: {human(total_params)}\")\n",
    "    lines.append(\"# GROUP COUNT (by first prefix before dot):\")\n",
    "    for g, c in sorted(groups.items(), key=lambda x: (-x[1], x[0])):\n",
    "        lines.append(f\"- {g}: {c}\")\n",
    "\n",
    "    # 预览一些键\n",
    "    preview = 30\n",
    "    lines.append(f\"# SAMPLE KEYS (first {preview}):\")\n",
    "    for i, (k, v) in enumerate(sd.items()):\n",
    "        if i >= preview: break\n",
    "        lines.append(f\"{k:80s} {tuple(v.shape)} {v.dtype}\")\n",
    "\n",
    "    lines.append(\"# \" + \"-\"*80)\n",
    "    lines.append(\"# FULL LIST (name -> shape, dtype):\")\n",
    "    for k, v in sd.items():\n",
    "        lines.append(f\"{k:80s} {tuple(v.shape)} {v.dtype}\")\n",
    "\n",
    "    # 可选：给你一个“去前缀”的镜像，方便和我们模型里的名字比\n",
    "    lines.append(\"# \" + \"-\"*80)\n",
    "    lines.append(\"# STRIPPED NAMES (model./module./keypoint_head.→head.) PREVIEW (first 30):\")\n",
    "    i = 0\n",
    "    for k, v in sd.items():\n",
    "        lines.append(f\"{strip_prefix(k):80s} {tuple(v.shape)} {v.dtype}\")\n",
    "        i += 1\n",
    "        if i >= 30: break\n",
    "\n",
    "    text = \"\\n\".join(lines)\n",
    "\n",
    "    # 打印到控制台（会很长）\n",
    "    print(text)\n",
    "\n",
    "    # 同时保存到文件，便于 grep / 对照\n",
    "    if save_all:\n",
    "        with open(out, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(text)\n",
    "        print(f\"\\n[OK] 完整键名与形状已写入：{out}\")\n",
    "\n",
    "\n",
    "main(\"pretrained/swin_tiny.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmpose-abu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
